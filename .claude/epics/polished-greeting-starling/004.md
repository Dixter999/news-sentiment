---
name: Implement Gemini Sentiment Analyzer
status: open
created: 2025-11-30T10:22:44Z
updated: 2025-11-30T10:22:44Z
github: https://github.com/Dixter999/news-sentiment/issues/6
depends_on: [002]
parallel: true
conflicts_with: []
---

# Task: Implement Gemini Sentiment Analyzer

## Description
Implement the `SentimentAnalyzer` class using Google's Gemini API to score economic events. Design an effective prompt for sentiment scoring (-1.0 to 1.0). Handle rate limits, API errors, and parse/validate LLM responses.

## TDD Requirements
**This project uses Test-Driven Development. You MUST:**
1. RED: Write failing test first (test_analyzer.py)
2. GREEN: Write minimal code to make test pass
3. REFACTOR: Clean up code while keeping tests green

See `.claude/rules/tdd.enforcement.md` for complete requirements.

## Acceptance Criteria
- [ ] Analyzer connects to Gemini API
- [ ] Prompt generates meaningful sentiment scores
- [ ] Scores are in range [-1.0, 1.0]
- [ ] Response includes reasoning for debugging
- [ ] Handles API rate limits with backoff
- [ ] Handles API errors gracefully (returns 0.0)
- [ ] Parses JSON response correctly
- [ ] Validates score range
- [ ] Stores raw response for debugging

## Technical Details

### File: `src/analyzer/gemini.py`

```python
import google.generativeai as genai
from typing import Dict, Optional
import json
import os
import time

class SentimentAnalyzer:
    """Gemini-based sentiment analyzer for economic events."""

    PROMPT_TEMPLATE = """
    Analyze the following economic event and provide a sentiment score.

    Event: {event_name}
    Currency: {currency}
    Impact Level: {impact}
    Actual: {actual}
    Forecast: {forecast}
    Previous: {previous}

    Score the sentiment impact on {currency} from -1.0 (strongly bearish) to 1.0 (strongly bullish).

    Consider:
    - Whether actual beat/missed forecast
    - The magnitude of the difference
    - Historical significance of this indicator
    - Market expectations

    Respond with JSON only:
    {{"score": <float>, "reasoning": "<brief explanation>"}}
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = "gemini-pro",
        max_retries: int = 3,
    ):
        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY not set")
        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel(model)
        self.max_retries = max_retries

    def analyze(self, event: Dict) -> Dict:
        """Analyze an economic event and return sentiment score.

        Args:
            event: Dict with event_name, currency, impact, actual, forecast, previous

        Returns:
            Dict with sentiment_score (-1.0 to 1.0) and raw_response
        """
        pass

    def _build_prompt(self, event: Dict) -> str:
        """Build the prompt for Gemini."""
        pass

    def _parse_response(self, response_text: str) -> Dict:
        """Parse and validate Gemini response."""
        pass

    def _validate_score(self, score: float) -> float:
        """Ensure score is in [-1.0, 1.0] range."""
        return max(-1.0, min(1.0, score))

    def _retry_with_backoff(self, func, *args, **kwargs):
        """Execute function with exponential backoff on failure."""
        pass
```

### Prompt Engineering Considerations
1. **Clear instruction**: Score from -1.0 (bearish) to 1.0 (bullish)
2. **Context**: Provide all relevant fields
3. **Reasoning**: Ask for explanation (helps debugging)
4. **JSON format**: Structured output for parsing
5. **Validation hints**: Include score interpretation

### Response Parsing
```python
def _parse_response(self, response_text: str) -> Dict:
    """Parse and validate Gemini response."""
    try:
        # Try to parse JSON
        result = json.loads(response_text)
        score = self._validate_score(float(result.get("score", 0.0)))
        return {
            "sentiment_score": score,
            "raw_response": {
                "reasoning": result.get("reasoning", ""),
                "full_response": response_text,
            },
        }
    except (json.JSONDecodeError, ValueError) as e:
        return {
            "sentiment_score": 0.0,
            "raw_response": {"error": str(e), "full_response": response_text},
        }
```

### Test File: `tests/test_analyzer.py`
```python
class TestSentimentAnalyzer:
    def test_analyze_returns_valid_score(self, mock_gemini):
        """Analyzer returns score in [-1.0, 1.0] range."""

    def test_positive_beat_returns_positive_score(self, mock_gemini):
        """When actual beats forecast, score is positive."""

    def test_negative_miss_returns_negative_score(self, mock_gemini):
        """When actual misses forecast, score is negative."""

    def test_handles_api_error(self, mock_gemini_error):
        """API errors return 0.0 with error in raw_response."""

    def test_handles_invalid_json(self, mock_gemini_invalid):
        """Invalid JSON response handled gracefully."""

    def test_validates_score_range(self):
        """Scores outside [-1, 1] are clamped."""

    def test_retry_on_rate_limit(self, mock_gemini_rate_limit):
        """Retries with backoff on rate limit error."""
```

## Dependencies
- [ ] Task 002: Database models (for event dict structure)

## Effort Estimate
- Size: M
- Hours: 8
- Parallel: true (can work alongside scraper)

## Definition of Done
- [ ] Tests written FIRST (RED phase)
- [ ] Code implemented (GREEN phase)
- [ ] Code refactored (REFACTOR phase)
- [ ] All tests passing
- [ ] Gemini API integration works
- [ ] Score validation implemented
- [ ] Error handling robust
- [ ] Rate limiting handled
