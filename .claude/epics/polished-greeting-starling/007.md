---
name: Documentation and README
status: open
created: 2025-11-30T10:22:44Z
updated: 2025-11-30T10:22:44Z
github: https://github.com/Dixter999/news-sentiment/issues/9
depends_on: [006]
parallel: true
conflicts_with: []
---

# Task: Documentation and README

## Description
Create comprehensive documentation including README.md with setup instructions, CLI usage, architecture overview, and verification steps. Update CLAUDE.md with project-specific instructions.

## TDD Requirements
Note: Documentation task - verify all examples and commands work correctly.

## Acceptance Criteria
- [ ] README.md with complete setup instructions
- [ ] CLI usage examples documented
- [ ] Architecture diagram included
- [ ] Database schema documented
- [ ] Verification steps documented
- [ ] CLAUDE.md with project context
- [ ] All code examples tested and working

## Technical Details

### README.md Structure

```markdown
# News Sentiment Service

Economic calendar scraping and LLM sentiment analysis for trading.

## Overview

This service scrapes Forex Factory economic calendar events using Playwright
and generates sentiment scores using Google's Gemini LLM.

### Architecture

```
Forex Factory Website
        ↓ (Playwright scraper)
Economic Event Data
        ↓ (Gemini LLM)
Sentiment Score (-1.0 to 1.0)
        ↓
PostgreSQL: economic_events table
        ↓
Trading RL Model
```

## Quick Start

### Prerequisites
- Python 3.11+
- PostgreSQL database
- Gemini API key

### Installation

```bash
# Clone repository
git clone https://github.com/Dixter999/news-sentiment.git
cd news-sentiment

# Create virtual environment
python -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -e ".[dev]"

# Install Playwright browser
playwright install chromium

# Configure environment
cp .env.example .env
# Edit .env with your credentials
```

### Database Setup

```bash
# Run migration
psql -h $DB_HOST -U $DB_USER -d $DB_NAME -f migrations/001_create_events_table.sql
```

## Usage

### Scrape Events
```bash
# Scrape this week's events
python src/main.py --scrape week

# Scrape today only
python src/main.py --scrape today

# Scrape entire month
python src/main.py --scrape month
```

### Analyze Events
```bash
# Analyze unscored events with Gemini
python src/main.py --analyze
```

### Full Pipeline
```bash
# Scrape and analyze
python src/main.py --scrape week --analyze

# Test run (no DB writes)
python src/main.py --scrape week --analyze --test-run
```

## Database Schema

### economic_events

| Column | Type | Description |
|--------|------|-------------|
| id | SERIAL | Primary key |
| timestamp | TIMESTAMPTZ | Event time (UTC) |
| currency | VARCHAR(3) | Currency code |
| event_name | VARCHAR(255) | Event description |
| impact | VARCHAR(20) | High/Medium/Low |
| actual | VARCHAR(50) | Actual value |
| forecast | VARCHAR(50) | Forecast value |
| previous | VARCHAR(50) | Previous value |
| sentiment_score | FLOAT | Gemini score (-1.0 to 1.0) |
| raw_response | JSONB | Full LLM response |

### Sentiment Score Interpretation

| Score | Interpretation |
|-------|----------------|
| 0.5 to 1.0 | Strongly Bullish |
| 0.1 to 0.5 | Mildly Bullish |
| -0.1 to 0.1 | Neutral |
| -0.5 to -0.1 | Mildly Bearish |
| -1.0 to -0.5 | Strongly Bearish |

## Verification

### 1. Test Scrape
```bash
python src/main.py --scrape week --test-run
```

### 2. Verify Database
```sql
SELECT timestamp, event_name, currency, impact, sentiment_score
FROM economic_events
WHERE sentiment_score IS NOT NULL
ORDER BY timestamp DESC
LIMIT 10;
```

### 3. Run Tests
```bash
pytest tests/ -v --cov=src
```

## Development

### Code Quality
```bash
# Format
black src/ tests/

# Lint
ruff check src/ tests/

# Type check
mypy src/
```

### Run Tests
```bash
pytest tests/ -v
```

## License
MIT
```

### CLAUDE.md Content

```markdown
# CLAUDE.md - News Sentiment Service

## Project Overview
Economic calendar scraping (Playwright) and LLM sentiment analysis (Gemini).

## Quick Commands
```bash
# Setup
pip install -e ".[dev]" && playwright install chromium

# Scrape and analyze
python src/main.py --scrape week --analyze

# Run tests
pytest tests/ -v
```

## Key Files
- `src/scraper/ff_scraper.py` - Playwright scraper
- `src/analyzer/gemini.py` - Gemini sentiment analyzer
- `src/main.py` - CLI orchestrator
- `src/database/models.py` - SQLAlchemy models

## Database
- Host: 10.0.0.4
- Database: ai_model
- Table: economic_events (includes sentiment_score, raw_response)

## Architecture
Playwright → Gemini → PostgreSQL → Trading Model

## Key Rules
- Follow TDD (test first)
- Sentiment scores in [-1.0, 1.0]
- Store raw_response for debugging
- Handle API rate limits
```

## Dependencies
- [ ] Task 006: Integration tests complete (for verified examples)

## Effort Estimate
- Size: S
- Hours: 3
- Parallel: true

## Definition of Done
- [ ] README.md complete
- [ ] CLAUDE.md updated
- [ ] All examples tested
- [ ] Architecture documented
- [ ] Schema documented
